{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rG8osmUUHTH"
      },
      "source": [
        "\n",
        "This notebook trains a ResNet50 convolutional neural network for image classification. It is trained on a custom dataset containing Colorado plants created using the iNaturalist API. The dataset contains:\n",
        "\n",
        "- 434 classes (plant species)\n",
        "- 180710 features (images)\n",
        "- Between 400 and 600 features per class\n",
        "\n",
        "Final performance metrics on validation dataset for model after initial training and two stages of gradual fine tuning:\n",
        "\n",
        "- val_accuracy: 0.9223 (92.2%)\n",
        "- val_loss: 0.3364\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Dv_SItTJmDyD"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "38hrwMQLmLOl"
      },
      "outputs": [],
      "source": [
        "# Constants\n",
        "TFRECORD_FILENAME = \"drive/MyDrive/resnet50_dataset.tfrecord\"\n",
        "IMAGE_SIZE = (224, 224)\n",
        "BATCH_SIZE = 64\n",
        "NUM_CLASSES = 434\n",
        "EPOCHS_INITIAL = 15\n",
        "EPOCHS_FINE = 10\n",
        "TOTAL_EXAMPLES = 180710"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "G08TAsOAmU9c"
      },
      "outputs": [],
      "source": [
        "# Function to provide additional pre-processing, specific to ResNet50's input\n",
        "def parse_example(example_proto):\n",
        "    feature_description = {\n",
        "        'image': tf.io.FixedLenFeature([], tf.string),\n",
        "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "    parsed = tf.io.parse_single_example(example_proto, feature_description)\n",
        "    image = tf.io.decode_jpeg(parsed['image'], channels=3)\n",
        "    image = tf.image.resize(image, IMAGE_SIZE)\n",
        "\n",
        "    image = tf.keras.applications.resnet.preprocess_input(tf.cast(image, tf.float32))\n",
        "    label = parsed['label']\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zZAMcBwQvryQ"
      },
      "outputs": [],
      "source": [
        "# Train/validation split of dataset with shuffling\n",
        "def get_finite_dataset():\n",
        "    raw_dataset = tf.data.TFRecordDataset(TFRECORD_FILENAME)\n",
        "    dataset = raw_dataset.map(parse_example, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "dataset = get_finite_dataset().shuffle(buffer_size=50000)\n",
        "train_size = int(0.8 * TOTAL_EXAMPLES)\n",
        "\n",
        "train_ds = dataset.take(train_size).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "val_ds = dataset.skip(train_size).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "IKWy8Fc9mZfO",
        "outputId": "ad24122e-f03c-4221-b93d-81d2794a3409"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)          │      <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">434</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">889,266</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)          │      \u001b[38;5;34m23,587,712\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m434\u001b[0m)                 │         \u001b[38;5;34m889,266\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,476,978</span> (93.37 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,476,978\u001b[0m (93.37 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">889,266</span> (3.39 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m889,266\u001b[0m (3.39 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Set up base moidel\n",
        "base_model = tf.keras.applications.ResNet50(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)\n",
        ")\n",
        "\n",
        "# Freeze base so it doesn't get overwritten\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = tf.keras.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "outputs = tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChzmxFrymd3X",
        "outputId": "971d29fb-0933-4ec1-db5d-db0661c2793a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "   2259/Unknown \u001b[1m112s\u001b[0m 35ms/step - accuracy: 0.3210 - loss: 3.1827"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 72ms/step - accuracy: 0.3210 - loss: 3.1826 - val_accuracy: 0.4937 - val_loss: 2.1994\n",
            "Epoch 2/15\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 65ms/step - accuracy: 0.5149 - loss: 2.0533 - val_accuracy: 0.5599 - val_loss: 1.8465\n",
            "Epoch 3/15\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 65ms/step - accuracy: 0.5665 - loss: 1.7849 - val_accuracy: 0.5943 - val_loss: 1.6752\n",
            "Epoch 4/15\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 65ms/step - accuracy: 0.5962 - loss: 1.6497 - val_accuracy: 0.6233 - val_loss: 1.5320\n",
            "Epoch 5/15\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 65ms/step - accuracy: 0.6185 - loss: 1.5398 - val_accuracy: 0.6443 - val_loss: 1.4411\n",
            "Epoch 6/15\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 65ms/step - accuracy: 0.6332 - loss: 1.4639 - val_accuracy: 0.6607 - val_loss: 1.3535\n",
            "Epoch 7/15\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 65ms/step - accuracy: 0.6450 - loss: 1.4131 - val_accuracy: 0.6708 - val_loss: 1.3091\n",
            "Epoch 8/15\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 65ms/step - accuracy: 0.6520 - loss: 1.3792 - val_accuracy: 0.6902 - val_loss: 1.2258\n",
            "Epoch 9/15\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 65ms/step - accuracy: 0.6584 - loss: 1.3385 - val_accuracy: 0.6981 - val_loss: 1.1799\n",
            "Epoch 10/15\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 65ms/step - accuracy: 0.6680 - loss: 1.3025 - val_accuracy: 0.6973 - val_loss: 1.1680\n",
            "Epoch 11/15\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 65ms/step - accuracy: 0.6729 - loss: 1.2798 - val_accuracy: 0.7126 - val_loss: 1.1270\n",
            "Epoch 12/15\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 65ms/step - accuracy: 0.6792 - loss: 1.2499 - val_accuracy: 0.7144 - val_loss: 1.1094\n",
            "Epoch 13/15\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 65ms/step - accuracy: 0.6816 - loss: 1.2370 - val_accuracy: 0.7287 - val_loss: 1.0468\n",
            "Epoch 14/15\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 65ms/step - accuracy: 0.6847 - loss: 1.2148 - val_accuracy: 0.7313 - val_loss: 1.0290\n",
            "Epoch 15/15\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 65ms/step - accuracy: 0.6879 - loss: 1.2144 - val_accuracy: 0.7384 - val_loss: 1.0004\n"
          ]
        }
      ],
      "source": [
        "# Initial training\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=EPOCHS_INITIAL,\n",
        "    validation_data=val_ds,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NeyElokNmhhi"
      },
      "outputs": [],
      "source": [
        "# In case fine tuning goes badly, we can save/load the model after initial training so we don't have to re-train completely\n",
        "model.save(\"initial_resnet50.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZZNbkQSmirk"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model(\"initial_resnet50.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gyjvDWmoCAMj"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "htC2E1commNH"
      },
      "outputs": [],
      "source": [
        "# Gradual unfreezing using ReduceLROnPlateau scheduler in case of plateau\n",
        "# Starting with last 20 layers\n",
        "for layer in base_model.layers[:-20]:\n",
        "    layer.trainable = False\n",
        "for layer in base_model.layers[-20:]:\n",
        "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "        layer.trainable = False\n",
        "    else:\n",
        "        layer.trainable = True\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifJfEVi2B_O1",
        "outputId": "fd19b766-8e19-4363-fb00-74d538d1c8c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 75ms/step - accuracy: 0.6625 - loss: 1.3115 - val_accuracy: 0.8069 - val_loss: 0.7871 - learning_rate: 1.0000e-05\n",
            "Epoch 2/5\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 69ms/step - accuracy: 0.7384 - loss: 0.9913 - val_accuracy: 0.8299 - val_loss: 0.6930 - learning_rate: 1.0000e-05\n",
            "Epoch 3/5\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 69ms/step - accuracy: 0.7710 - loss: 0.8538 - val_accuracy: 0.8439 - val_loss: 0.6476 - learning_rate: 1.0000e-05\n",
            "Epoch 4/5\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 69ms/step - accuracy: 0.7934 - loss: 0.7601 - val_accuracy: 0.8572 - val_loss: 0.5819 - learning_rate: 1.0000e-05\n",
            "Epoch 5/5\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 69ms/step - accuracy: 0.8157 - loss: 0.6750 - val_accuracy: 0.8689 - val_loss: 0.5438 - learning_rate: 1.0000e-05\n"
          ]
        }
      ],
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history_fine_stage1 = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=5,\n",
        "    callbacks=[lr_scheduler]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "BaoU08l4CFCD"
      },
      "outputs": [],
      "source": [
        "model.save(\"stage1_resnet50.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "BMzhaH5fHDQi"
      },
      "outputs": [],
      "source": [
        "# Fine tuning for last 40 layers\n",
        "for layer in base_model.layers[:-40]:\n",
        "    layer.trainable = False\n",
        "for layer in base_model.layers[-40:]:\n",
        "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "        layer.trainable = False\n",
        "    else:\n",
        "        layer.trainable = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sjWsyvZHFrQ",
        "outputId": "1108cf29-4b29-4bc1-e2cd-df2e051f8af4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "   2259/Unknown \u001b[1m99s\u001b[0m 36ms/step - accuracy: 0.8339 - loss: 0.6041"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 69ms/step - accuracy: 0.8339 - loss: 0.6041 - val_accuracy: 0.8798 - val_loss: 0.5007 - learning_rate: 1.0000e-05\n",
            "Epoch 2/5\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 69ms/step - accuracy: 0.8532 - loss: 0.5352 - val_accuracy: 0.8933 - val_loss: 0.4488 - learning_rate: 1.0000e-05\n",
            "Epoch 3/5\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 69ms/step - accuracy: 0.8654 - loss: 0.4833 - val_accuracy: 0.9019 - val_loss: 0.4084 - learning_rate: 1.0000e-05\n",
            "Epoch 4/5\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 69ms/step - accuracy: 0.8800 - loss: 0.4311 - val_accuracy: 0.9107 - val_loss: 0.3792 - learning_rate: 1.0000e-05\n",
            "Epoch 5/5\n",
            "\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 69ms/step - accuracy: 0.8925 - loss: 0.3861 - val_accuracy: 0.9223 - val_loss: 0.3364 - learning_rate: 1.0000e-05\n"
          ]
        }
      ],
      "source": [
        "history_fine_stage2 = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=5,\n",
        "    callbacks=[lr_scheduler]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "A9OnXDBGHH-q"
      },
      "outputs": [],
      "source": [
        "model.save(\"stage2_resnet50.keras\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
